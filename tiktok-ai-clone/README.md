# AI TikTok Clone

A modern TikTok clone with AI-generated content, featuring an infinite scroll experience similar to TikTok.

## Features

- **AI-Generated Content**: All videos, descriptions, and user profiles are generated by AI
- **Local Video Integration**: Uses local video files to avoid CORS issues and improve development experience
- **GPT-4o Descriptions**: Extracts frames from videos and uses GPT-4o to generate engaging descriptions
- **Infinite Scroll**: Smooth scrolling experience with automatic loading of new content
- **Responsive Design**: Works on both mobile and desktop devices
- **Modern UI**: Clean and intuitive interface inspired by TikTok

## Tech Stack

- React
- TypeScript
- Emotion (CSS-in-JS)
- Vite (Build tool)
- React Router (Navigation)
- Framer Motion (Animations)
- OpenAI API (GPT-4o)

## Getting Started

### Prerequisites

- Node.js (v14 or higher)
- npm or yarn
- OpenAI API key

### Installation

1. Clone the repository
```bash
git clone <repository-url>
cd tiktok-ai-clone
```

2. Install dependencies
```bash
npm install
```

3. Set up environment variables
Create a `.env` file in the root directory with the following variables:
```
VITE_OPENAI_API_KEY=your_openai_api_key_here
```

### Local Videos

This project uses local video files stored in the `public/assets/videos` directory. The metadata for these videos is stored in `public/assets/data/video_metadata.json`.

If you want to add more videos:
1. Place MP4 video files in the `public/assets/videos` directory
2. Update the `public/assets/data/video_metadata.json` file with metadata for each video
3. Make sure each video entry in the JSON file has a `video_path` property pointing to the correct file path

See `public/assets/README.md` for more details.

4. Start the development server
```bash
npm run dev
```

5. Open your browser and navigate to `http://localhost:3000`

## Troubleshooting

If you encounter any issues while running the application, try these solutions:

### WebSocket Connection Failures

If you see errors like:
```
WebSocket connection to 'ws://localhost:3000/?token=...' failed
```

This is related to Vite's Hot Module Replacement (HMR). The application will still work, but you may need to manually refresh the page to see changes. We've implemented a fallback mechanism that will automatically switch to HTTP-based HMR if WebSocket fails.

### Maximum Update Depth Exceeded

If you see errors like:
```
Maximum update depth exceeded. This can happen when a component calls setState inside useEffect...
```

This is typically caused by an infinite loop in React's rendering cycle. We've fixed the most common causes of this issue, but if it persists:

1. Check for any state updates inside useEffect hooks without proper dependency arrays
2. Restart the development server with `npm run dev`
3. Clear your browser cache and reload the page

### React Prop Warnings

If you see warnings like:
```
React does not recognize the `isActive` prop on a DOM element...
```

This is caused by passing custom props directly to DOM elements. We've fixed this by:

1. Creating separate styled components for active and inactive states
2. Using custom wrapper components that handle the `isActive` prop without passing it to the DOM
3. Using proper React patterns for conditional rendering

If you encounter similar warnings with other props, follow the same pattern:
- Create separate styled components for different states
- Use a wrapper component to handle the prop and render the appropriate styled component

### Hugging Face API Errors

If you see errors like:
```
GET https://datasets-server.huggingface.co/rows?dataset=HuggingFaceFV/finevideo&config=default&split=train&offset=0&limit=5 500 (Internal Server Error)
```

or

```
Failed to fetch from Hugging Face API: {"error":"Authentication check on the Hugging Face Hub failed or timed out..."}
```

These errors indicate issues with the Hugging Face API. The application is designed to handle these errors gracefully:

1. It will automatically fall back to using sample videos with generated metadata
2. The app will continue to function normally, just without real FineVideo metadata
3. You can still see the core functionality of extracting frames and generating descriptions

To fix these issues:
- Check that your Hugging Face API key is correct in the `.env` file
- The API might be experiencing temporary issues - try again later
- You may need to request access to the FineVideo dataset on Hugging Face

### Video Loading Errors

If you see errors like:
```
GET https://some-video-url.mp4 403 (Forbidden)
```

or

```
Error processing FineVideo: Error: Error loading video
```

These errors occur when the app can't load the sample videos. We've updated the app to:

1. Use different sample videos from sources that allow direct access
2. Add better error handling to continue even if some videos fail to load
3. Implement timeouts to prevent hanging requests

If you still encounter these errors:
- Check your internet connection
- The video sources might be temporarily unavailable
- The app will still function with any videos it can successfully load

### Videos Not Loading or Playing

If videos aren't loading or playing properly:

1. Check your network connection
2. Try using a different browser (Chrome works best for video playback)
3. Clear your browser cache and reload the page
4. Check the browser console for specific error messages
5. The app will fall back to sample videos if it can't fetch from the FineVideo dataset

## Project Structure

```
tiktok-ai-clone/
├── src/
│   ├── components/     # Reusable UI components
│   ├── hooks/          # Custom React hooks
│   ├── pages/          # Page components
│   ├── services/       # API and service functions
│   │   ├── aiService.ts          # AI content generation
│   │   ├── fineVideoService.ts   # FineVideo integration
│   │   └── openaiService.ts      # OpenAI API integration
│   ├── styles/         # Global styles
│   ├── utils/          # Utility functions
│   ├── App.tsx         # Main App component
│   └── main.tsx        # Entry point
├── public/             # Static assets
├── index.html          # HTML template
├── package.json        # Dependencies and scripts
├── tsconfig.json       # TypeScript configuration
└── vite.config.ts      # Vite configuration
```

## How It Works

The application integrates with Hugging Face's FineVideo dataset to fetch 15-second video clips. For each video:

1. A frame is extracted from the middle of the clip
2. The frame is sent to OpenAI's GPT-4o API along with video metadata
3. GPT-4o generates an engaging, TikTok-style description for the video
4. AI-generated agent personalities interact with the content

The infinite scroll is implemented using the Intersection Observer API, which detects when the user has scrolled to the bottom of the feed and triggers loading of new content.

## FineVideo Integration

The [FineVideo dataset](https://huggingface.co/datasets/HuggingFaceFV/finevideo) from Hugging Face contains over 43,000 videos with rich metadata including:

- Content categories
- Scene descriptions
- Character information
- Narrative progression
- Mood analysis

### Efficient Data Handling

**Important**: This application does NOT download the entire FineVideo dataset (which is ~600GB). Instead, it:

1. Fetches only a small sample of metadata from the dataset using the Hugging Face API
2. Uses the metadata to generate descriptions with GPT-4o
3. For development purposes, pairs the metadata with sample videos to simulate the experience

This approach allows you to develop and test the application without downloading the entire dataset. When you run `npm run dev`, the app will:

1. Try to fetch metadata from a few FineVideo samples
2. Use sample videos as placeholders for the actual video content
3. Generate descriptions based on the real metadata and frames from the sample videos

If you want to use the actual videos from FineVideo in production, you would need to implement a more sophisticated approach to fetch and process the video content.

## Future Enhancements

- Implement full integration with the Hugging Face API for FineVideo access
- Add video trimming functionality to ensure all clips are exactly 15 seconds
- Implement user authentication and personalized feeds
- Add video recording and uploading functionality
- Enhance agent interactions based on video content
- Implement content recommendation algorithms

## License

This project is licensed under the MIT License - see the LICENSE file for details. 